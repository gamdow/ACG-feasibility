Intel(R) Advisor can now assist with vectorization and show optimization
  report messages with your source code.
See "https://software.intel.com/en-us/intel-advisor-xe" for details.


    Report from: Interprocedural optimizations [ipo]

INLINING OPTION VALUES:
  -inline-factor: 100
  -inline-min-size: 30
  -inline-max-size: 230
  -inline-max-total-size: 2000
  -inline-max-per-routine: disabled
  -inline-max-per-compile: disabled


Begin optimization report for: main(int, char **)

    Report from: Interprocedural optimizations [ipo]

INLINE REPORT: (main(int, char **)) [1] wave_ops.cpp(57,1)
  -> INLINE: (76,5) ops_decl_const2<double>(const char *, int, const char *, double *)
    -> INLINE: /root/OPS/ops/c/include/ops_lib_cpp.h:(83,7) type_error(const double *, const char *)
  -> INLINE: (77,5) ops_decl_const2<double>(const char *, int, const char *, double *)
    -> INLINE: /root/OPS/ops/c/include/ops_lib_cpp.h:(83,7) type_error(const double *, const char *)
  -> INLINE: (78,5) ops_decl_const2<double>(const char *, int, const char *, double *)
    -> INLINE: /root/OPS/ops/c/include/ops_lib_cpp.h:(83,7) type_error(const double *, const char *)
  -> INLINE: (79,5) ops_decl_const2<double>(const char *, int, const char *, double *)
    -> INLINE: /root/OPS/ops/c/include/ops_lib_cpp.h:(83,7) type_error(const double *, const char *)
  -> INLINE: (80,5) ops_decl_const2<double>(const char *, int, const char *, double *)
    -> INLINE: /root/OPS/ops/c/include/ops_lib_cpp.h:(83,7) type_error(const double *, const char *)
  -> INLINE: (81,5) ops_decl_const2<double>(const char *, int, const char *, double *)
    -> INLINE: /root/OPS/ops/c/include/ops_lib_cpp.h:(83,7) type_error(const double *, const char *)
  -> INLINE: (82,5) ops_decl_const2<double>(const char *, int, const char *, double *)
    -> INLINE: /root/OPS/ops/c/include/ops_lib_cpp.h:(83,7) type_error(const double *, const char *)
  -> INLINE: (83,5) ops_decl_const2<int>(const char *, int, const char *, int *)
    -> INLINE: /root/OPS/ops/c/include/ops_lib_cpp.h:(83,7) type_error(const int *, const char *)
  -> INLINE: (99,10) ops_decl_dat<double>(ops_block, int, int *, int *, int *, int *, double *, const char *, const char *)
    -> INLINE: /root/OPS/ops/c/include/ops_lib_cpp.h:(142,7) type_error(const double *, const char *)
  -> INLINE: (100,10) ops_decl_dat<double>(ops_block, int, int *, int *, int *, int *, double *, const char *, const char *)
    -> INLINE: /root/OPS/ops/c/include/ops_lib_cpp.h:(142,7) type_error(const double *, const char *)
  -> INLINE: (101,14) ops_decl_dat<double>(ops_block, int, int *, int *, int *, int *, double *, const char *, const char *)
    -> INLINE: /root/OPS/ops/c/include/ops_lib_cpp.h:(142,7) type_error(const double *, const char *)
  -> INLINE: (102,10) ops_decl_dat<double>(ops_block, int, int *, int *, int *, int *, double *, const char *, const char *)
    -> INLINE: /root/OPS/ops/c/include/ops_lib_cpp.h:(142,7) type_error(const double *, const char *)
  -> (135,4) ops_par_loop_wave_block0_5_kernel(const char *, ops_block, int, int *, ops_arg, ops_arg)
  -> (150,7) ops_par_loop_wave_block0_4_kernel(const char *, ops_block, int, int *, ops_arg, ops_arg)
  -> (158,10) ops_par_loop_wave_block0_0_kernel(const char *, ops_block, int, int *, ops_arg, ops_arg)
  -> (163,10) ops_par_loop_wave_block0_1_kernel(const char *, ops_block, int, int *, ops_arg, ops_arg)
  -> (168,10) ops_par_loop_wave_block0_2_kernel(const char *, ops_block, int, int *, ops_arg, ops_arg, ops_arg, ops_arg)
  -> INLINE: (172,63) ops_arg_gbl<double>(double *, int, const char *, ops_access)
  -> (175,10) ops_par_loop_wave_block0_3_kernel(const char *, ops_block, int, int *, ops_arg, ops_arg, ops_arg)
  -> INLINE: (178,63) ops_arg_gbl<double>(double *, int, const char *, ops_access)


    Report from: Loop nest, Vector & Auto-parallelization optimizations [loop, vec, par]


LOOP BEGIN at wave_ops.cpp(147,4)
   remark #15344: loop was not vectorized: vector dependence prevents vectorization. First dependence is shown below. Use level 5 report for details
   remark #15346: vector dependence: assumed ANTI dependence between iter_range4 (149:25) and iter_range3 (175:10)

   LOOP BEGIN at wave_ops.cpp(155,7)
      remark #15344: loop was not vectorized: vector dependence prevents vectorization. First dependence is shown below. Use level 5 report for details
      remark #15346: vector dependence: assumed OUTPUT dependence between call:?1memset (157:28) and call:ops_halo_transfer(ops_halo_group) (183:10)
   LOOP END
LOOP END

    Report from: Code generation optimizations [cg]

wave_ops.cpp(97,15):remark #34000: call to memset implemented inline with stores with proven (alignment, offset): (16, 0)
wave_ops.cpp(104,24):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (16, 0), and destination (alignment, offset): (16, 0)
wave_ops.cpp(106,24):remark #34000: call to memset implemented inline with stores with proven (alignment, offset): (16, 0)
wave_ops.cpp(113,23):remark #34000: call to memset implemented inline with stores with proven (alignment, offset): (16, 0)
wave_ops.cpp(135,4):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (16, 0), and destination (alignment, offset): (1, 0)
wave_ops.cpp(135,4):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (16, 0), and destination (alignment, offset): (1, 0)
wave_ops.cpp(150,7):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (16, 0), and destination (alignment, offset): (1, 0)
wave_ops.cpp(150,7):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (16, 0), and destination (alignment, offset): (1, 0)
wave_ops.cpp(157,28):remark #34000: call to memset implemented inline with stores with proven (alignment, offset): (16, 0)
wave_ops.cpp(158,10):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (16, 0), and destination (alignment, offset): (1, 0)
wave_ops.cpp(158,10):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (16, 0), and destination (alignment, offset): (1, 0)
wave_ops.cpp(162,28):remark #34000: call to memset implemented inline with stores with proven (alignment, offset): (16, 0)
wave_ops.cpp(163,10):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (16, 0), and destination (alignment, offset): (1, 0)
wave_ops.cpp(163,10):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (16, 0), and destination (alignment, offset): (1, 0)
wave_ops.cpp(168,10):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (16, 0), and destination (alignment, offset): (1, 0)
wave_ops.cpp(168,10):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (16, 0), and destination (alignment, offset): (1, 0)
wave_ops.cpp(168,10):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (16, 0), and destination (alignment, offset): (1, 0)
wave_ops.cpp(168,10):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (16, 0), and destination (alignment, offset): (1, 0)
wave_ops.cpp(175,10):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (16, 0), and destination (alignment, offset): (1, 0)
wave_ops.cpp(175,10):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (16, 0), and destination (alignment, offset): (1, 0)
wave_ops.cpp(175,10):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (16, 0), and destination (alignment, offset): (1, 0)
wave_ops.cpp(57,1):remark #34051: REGISTER ALLOCATION : [main] wave_ops.cpp:57

    Hardware registers
        Reserved     :    2[ rsp rip]
        Available    :   39[ rax rdx rcx rbx rbp rsi rdi r8-r15 mm0-mm7 zmm0-zmm15]
        Callee-save  :    6[ rbx rbp r12-r15]
        Assigned     :   26[ rax rdx rcx rbx rsi rdi r8-r15 zmm0-zmm11]
        
    Routine temporaries
        Total         :     437
            Global    :      60
            Local     :     377
        Regenerable   :     253
        Spilled       :      13
        
    Routine stack
        Variables     :    1024 bytes*
            Reads     :      71 [3.83e+05 ~ 21.9%]
            Writes    :      30 [6.50e+04 ~ 3.7%]
        Spills        :      64 bytes*
            Reads     :      12 [5.75e+04 ~ 3.3%]
            Writes    :       8 [2.51e+03 ~ 0.1%]
    
    Notes
    
        *Non-overlapping variables and spills may share stack space,
         so the total stack size might be less than this.
    

===========================================================================

Begin optimization report for: ops_par_loop_wave_block0_4_kernel(const char *, ops_block, int, int *, ops_arg, ops_arg)

    Report from: Interprocedural optimizations [ipo]

INLINE REPORT: (ops_par_loop_wave_block0_4_kernel(const char *, ops_block, int, int *, ops_arg, ops_arg)) [2] ./MPI_OpenMP/wave_block0_4_kernel_omp_kernel.cpp(21,30)
  -> INLINE: (144,9) wave_block0_4_kernel(const double *, double *)
  -> INLINE: (155,7) wave_block0_4_kernel(const double *, double *)


    Report from: OpenMP optimizations [openmp]

./MPI_OpenMP/wave_block0_4_kernel_omp_kernel.cpp(107:3-107:3):OMP:_Z33ops_par_loop_wave_block0_4_kernelPKcP14ops_block_coreiPi7ops_argS4_:  OpenMP DEFINED LOOP WAS PARALLELIZED

    Report from: Loop nest, Vector & Auto-parallelization optimizations [loop, vec, par]


LOOP BEGIN at ./MPI_OpenMP/wave_block0_4_kernel_omp_kernel.cpp(108,3)
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at ./MPI_OpenMP/wave_block0_4_kernel_omp_kernel.cpp(124,5)
      remark #25399: memcopy generated
      remark #15542: loop was not vectorized: inner loop was already vectorized

      LOOP BEGIN at ./MPI_OpenMP/wave_block0_4_kernel_omp_kernel.cpp(124,5)
      <Peeled loop for vectorization>
      LOOP END

      LOOP BEGIN at ./MPI_OpenMP/wave_block0_4_kernel_omp_kernel.cpp(124,5)
         remark #15300: LOOP WAS VECTORIZED
      LOOP END

      LOOP BEGIN at ./MPI_OpenMP/wave_block0_4_kernel_omp_kernel.cpp(124,5)
      <Alternate Alignment Vectorized Loop>
      LOOP END

      LOOP BEGIN at ./MPI_OpenMP/wave_block0_4_kernel_omp_kernel.cpp(124,5)
      <Remainder loop for vectorization>
      LOOP END
   LOOP END

   LOOP BEGIN at ./MPI_OpenMP/wave_block0_4_kernel_omp_kernel.cpp(133,5)
      remark #25399: memcopy generated
      remark #15542: loop was not vectorized: inner loop was already vectorized

      LOOP BEGIN at ./MPI_OpenMP/wave_block0_4_kernel_omp_kernel.cpp(133,5)
         remark #15300: LOOP WAS VECTORIZED
      LOOP END

      LOOP BEGIN at ./MPI_OpenMP/wave_block0_4_kernel_omp_kernel.cpp(133,5)
      <Remainder loop for vectorization>
      LOOP END
   LOOP END

   LOOP BEGIN at ./MPI_OpenMP/wave_block0_4_kernel_omp_kernel.cpp(140,5)
      remark #15542: loop was not vectorized: inner loop was already vectorized

      LOOP BEGIN at ./MPI_OpenMP/wave_block0_4_kernel_omp_kernel.cpp(143,7)
         remark #15301: SIMD LOOP WAS VECTORIZED
      LOOP END
   LOOP END

   LOOP BEGIN at ./MPI_OpenMP/wave_block0_4_kernel_omp_kernel.cpp(153,5)
      remark #15335: loop was not vectorized: vectorization possible but seems inefficient. Use vector always directive or -vec-threshold0 to override 
      remark #25439: unrolled with remainder by 2  
   LOOP END

   LOOP BEGIN at ./MPI_OpenMP/wave_block0_4_kernel_omp_kernel.cpp(153,5)
   <Remainder>
   LOOP END
LOOP END

    Report from: Code generation optimizations [cg]

./MPI_OpenMP/wave_block0_4_kernel_omp_kernel.cpp(27,23):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (8, 0), and destination (alignment, offset): (16, 0)
./MPI_OpenMP/wave_block0_4_kernel_omp_kernel.cpp(27,29):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (8, 0), and destination (alignment, offset): (16, 8)
./MPI_OpenMP/wave_block0_4_kernel_omp_kernel.cpp(124,5):remark #34026: call to memcpy implemented as a call to optimized library version
./MPI_OpenMP/wave_block0_4_kernel_omp_kernel.cpp(133,5):remark #34026: call to memcpy implemented as a call to optimized library version
./MPI_OpenMP/wave_block0_4_kernel_omp_kernel.cpp(21,30):remark #34051: REGISTER ALLOCATION : [_Z33ops_par_loop_wave_block0_4_kernelPKcP14ops_block_coreiPi7ops_argS4_] ./MPI_OpenMP/wave_block0_4_kernel_omp_kernel.cpp:21

    Hardware registers
        Reserved     :    2[ rsp rip]
        Available    :   39[ rax rdx rcx rbx rbp rsi rdi r8-r15 mm0-mm7 zmm0-zmm15]
        Callee-save  :    6[ rbx rbp r12-r15]
        Assigned     :   21[ rax rdx rcx rbx rbp rsi rdi r8-r15 zmm0-zmm5]
        
    Routine temporaries
        Total         :     344
            Global    :      88
            Local     :     256
        Regenerable   :     101
        Spilled       :      34
        
    Routine stack
        Variables     :     208 bytes*
            Reads     :      20 [1.24e+01 ~ 1.0%]
            Writes    :      22 [7.70e+01 ~ 6.2%]
        Spills        :     320 bytes*
            Reads     :      64 [1.38e+02 ~ 11.0%]
            Writes    :      48 [4.11e+01 ~ 3.3%]
    
    Notes
    
        *Non-overlapping variables and spills may share stack space,
         so the total stack size might be less than this.
    

===========================================================================

Begin optimization report for: ops_par_loop_wave_block0_0_kernel(const char *, ops_block, int, int *, ops_arg, ops_arg)

    Report from: Interprocedural optimizations [ipo]

INLINE REPORT: (ops_par_loop_wave_block0_0_kernel(const char *, ops_block, int, int *, ops_arg, ops_arg)) [3] ./MPI_OpenMP/wave_block0_0_kernel_omp_kernel.cpp(21,30)
  -> INLINE: (144,9) wave_block0_0_kernel(const double *, double *)
  -> INLINE: (155,7) wave_block0_0_kernel(const double *, double *)


    Report from: OpenMP optimizations [openmp]

./MPI_OpenMP/wave_block0_0_kernel_omp_kernel.cpp(107:3-107:3):OMP:_Z33ops_par_loop_wave_block0_0_kernelPKcP14ops_block_coreiPi7ops_argS4_:  OpenMP DEFINED LOOP WAS PARALLELIZED

    Report from: Loop nest, Vector & Auto-parallelization optimizations [loop, vec, par]


LOOP BEGIN at ./MPI_OpenMP/wave_block0_0_kernel_omp_kernel.cpp(108,3)
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at ./MPI_OpenMP/wave_block0_0_kernel_omp_kernel.cpp(124,5)
      remark #25399: memcopy generated
      remark #15542: loop was not vectorized: inner loop was already vectorized

      LOOP BEGIN at ./MPI_OpenMP/wave_block0_0_kernel_omp_kernel.cpp(124,5)
      <Peeled loop for vectorization>
      LOOP END

      LOOP BEGIN at ./MPI_OpenMP/wave_block0_0_kernel_omp_kernel.cpp(124,5)
         remark #15300: LOOP WAS VECTORIZED
      LOOP END

      LOOP BEGIN at ./MPI_OpenMP/wave_block0_0_kernel_omp_kernel.cpp(124,5)
      <Alternate Alignment Vectorized Loop>
      LOOP END

      LOOP BEGIN at ./MPI_OpenMP/wave_block0_0_kernel_omp_kernel.cpp(124,5)
      <Remainder loop for vectorization>
      LOOP END
   LOOP END

   LOOP BEGIN at ./MPI_OpenMP/wave_block0_0_kernel_omp_kernel.cpp(133,5)
      remark #25399: memcopy generated
      remark #15542: loop was not vectorized: inner loop was already vectorized

      LOOP BEGIN at ./MPI_OpenMP/wave_block0_0_kernel_omp_kernel.cpp(133,5)
         remark #15300: LOOP WAS VECTORIZED
      LOOP END

      LOOP BEGIN at ./MPI_OpenMP/wave_block0_0_kernel_omp_kernel.cpp(133,5)
      <Remainder loop for vectorization>
      LOOP END
   LOOP END

   LOOP BEGIN at ./MPI_OpenMP/wave_block0_0_kernel_omp_kernel.cpp(140,5)
      remark #15542: loop was not vectorized: inner loop was already vectorized

      LOOP BEGIN at ./MPI_OpenMP/wave_block0_0_kernel_omp_kernel.cpp(143,7)
         remark #15301: SIMD LOOP WAS VECTORIZED
      LOOP END
   LOOP END

   LOOP BEGIN at ./MPI_OpenMP/wave_block0_0_kernel_omp_kernel.cpp(153,5)
      remark #15300: LOOP WAS VECTORIZED
   LOOP END

   LOOP BEGIN at ./MPI_OpenMP/wave_block0_0_kernel_omp_kernel.cpp(153,5)
   <Remainder loop for vectorization>
   LOOP END
LOOP END

    Report from: Code generation optimizations [cg]

./MPI_OpenMP/wave_block0_0_kernel_omp_kernel.cpp(12,127):remark #34055: adjacent dense (unit-strided stencil) loads are not optimized. Details: stride { 8 }, step { 8 }, types { F64-V128, F64-V128 }, number of elements { 2 }, select mask { 0x000000003 }.
./MPI_OpenMP/wave_block0_0_kernel_omp_kernel.cpp(12,175):remark #34055: adjacent dense (unit-strided stencil) loads are not optimized. Details: stride { 8 }, step { 8 }, types { F64-V128, F64-V128 }, number of elements { 2 }, select mask { 0x000000003 }.
./MPI_OpenMP/wave_block0_0_kernel_omp_kernel.cpp(12,27):remark #34069: adjacent sparse (strided) loads seem unprofitable to optimize. Details: stride { unknown }, types { F64-V128, F64-V128 }, number of elements { 2 }, select mask { 0x000000003 }.
./MPI_OpenMP/wave_block0_0_kernel_omp_kernel.cpp(12,77):remark #34069: adjacent sparse (strided) loads seem unprofitable to optimize. Details: stride { unknown }, types { F64-V128, F64-V128 }, number of elements { 2 }, select mask { 0x000000003 }.
./MPI_OpenMP/wave_block0_0_kernel_omp_kernel.cpp(12,127):remark #34069: adjacent sparse (strided) loads seem unprofitable to optimize. Details: stride { unknown }, types { F64-V128, F64-V128 }, number of elements { 2 }, select mask { 0x000000003 }.
./MPI_OpenMP/wave_block0_0_kernel_omp_kernel.cpp(12,175):remark #34069: adjacent sparse (strided) loads seem unprofitable to optimize. Details: stride { unknown }, types { F64-V128, F64-V128 }, number of elements { 2 }, select mask { 0x000000003 }.
./MPI_OpenMP/wave_block0_0_kernel_omp_kernel.cpp(27,23):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (8, 0), and destination (alignment, offset): (16, 0)
./MPI_OpenMP/wave_block0_0_kernel_omp_kernel.cpp(27,29):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (8, 0), and destination (alignment, offset): (16, 8)
./MPI_OpenMP/wave_block0_0_kernel_omp_kernel.cpp(124,5):remark #34026: call to memcpy implemented as a call to optimized library version
./MPI_OpenMP/wave_block0_0_kernel_omp_kernel.cpp(133,5):remark #34026: call to memcpy implemented as a call to optimized library version
./MPI_OpenMP/wave_block0_0_kernel_omp_kernel.cpp(21,30):remark #34051: REGISTER ALLOCATION : [_Z33ops_par_loop_wave_block0_0_kernelPKcP14ops_block_coreiPi7ops_argS4_] ./MPI_OpenMP/wave_block0_0_kernel_omp_kernel.cpp:21

    Hardware registers
        Reserved     :    2[ rsp rip]
        Available    :   39[ rax rdx rcx rbx rbp rsi rdi r8-r15 mm0-mm7 zmm0-zmm15]
        Callee-save  :    6[ rbx rbp r12-r15]
        Assigned     :   28[ rax rdx rcx rbx rbp rsi rdi r8-r15 zmm0-zmm12]
        
    Routine temporaries
        Total         :     430
            Global    :      96
            Local     :     334
        Regenerable   :     103
        Spilled       :      32
        
    Routine stack
        Variables     :     208 bytes*
            Reads     :      20 [1.24e+01 ~ 0.2%]
            Writes    :      22 [7.70e+01 ~ 1.4%]
        Spills        :     296 bytes*
            Reads     :      61 [1.31e+02 ~ 2.3%]
            Writes    :      45 [3.98e+01 ~ 0.7%]
    
    Notes
    
        *Non-overlapping variables and spills may share stack space,
         so the total stack size might be less than this.
    

===========================================================================

Begin optimization report for: ops_par_loop_wave_block0_1_kernel(const char *, ops_block, int, int *, ops_arg, ops_arg)

    Report from: Interprocedural optimizations [ipo]

INLINE REPORT: (ops_par_loop_wave_block0_1_kernel(const char *, ops_block, int, int *, ops_arg, ops_arg)) [4] ./MPI_OpenMP/wave_block0_1_kernel_omp_kernel.cpp(21,30)
  -> INLINE: (144,9) wave_block0_1_kernel(const double *, double *)
  -> INLINE: (155,7) wave_block0_1_kernel(const double *, double *)


    Report from: OpenMP optimizations [openmp]

./MPI_OpenMP/wave_block0_1_kernel_omp_kernel.cpp(107:3-107:3):OMP:_Z33ops_par_loop_wave_block0_1_kernelPKcP14ops_block_coreiPi7ops_argS4_:  OpenMP DEFINED LOOP WAS PARALLELIZED

    Report from: Loop nest, Vector & Auto-parallelization optimizations [loop, vec, par]


LOOP BEGIN at ./MPI_OpenMP/wave_block0_1_kernel_omp_kernel.cpp(108,3)
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at ./MPI_OpenMP/wave_block0_1_kernel_omp_kernel.cpp(124,5)
      remark #25399: memcopy generated
      remark #15542: loop was not vectorized: inner loop was already vectorized

      LOOP BEGIN at ./MPI_OpenMP/wave_block0_1_kernel_omp_kernel.cpp(124,5)
      <Peeled loop for vectorization>
      LOOP END

      LOOP BEGIN at ./MPI_OpenMP/wave_block0_1_kernel_omp_kernel.cpp(124,5)
         remark #15300: LOOP WAS VECTORIZED
      LOOP END

      LOOP BEGIN at ./MPI_OpenMP/wave_block0_1_kernel_omp_kernel.cpp(124,5)
      <Alternate Alignment Vectorized Loop>
      LOOP END

      LOOP BEGIN at ./MPI_OpenMP/wave_block0_1_kernel_omp_kernel.cpp(124,5)
      <Remainder loop for vectorization>
      LOOP END
   LOOP END

   LOOP BEGIN at ./MPI_OpenMP/wave_block0_1_kernel_omp_kernel.cpp(133,5)
      remark #25399: memcopy generated
      remark #15542: loop was not vectorized: inner loop was already vectorized

      LOOP BEGIN at ./MPI_OpenMP/wave_block0_1_kernel_omp_kernel.cpp(133,5)
         remark #15300: LOOP WAS VECTORIZED
      LOOP END

      LOOP BEGIN at ./MPI_OpenMP/wave_block0_1_kernel_omp_kernel.cpp(133,5)
      <Remainder loop for vectorization>
      LOOP END
   LOOP END

   LOOP BEGIN at ./MPI_OpenMP/wave_block0_1_kernel_omp_kernel.cpp(140,5)
      remark #15542: loop was not vectorized: inner loop was already vectorized

      LOOP BEGIN at ./MPI_OpenMP/wave_block0_1_kernel_omp_kernel.cpp(143,7)
         remark #15301: SIMD LOOP WAS VECTORIZED
      LOOP END
   LOOP END

   LOOP BEGIN at ./MPI_OpenMP/wave_block0_1_kernel_omp_kernel.cpp(153,5)
      remark #15335: loop was not vectorized: vectorization possible but seems inefficient. Use vector always directive or -vec-threshold0 to override 
      remark #25439: unrolled with remainder by 2  
   LOOP END

   LOOP BEGIN at ./MPI_OpenMP/wave_block0_1_kernel_omp_kernel.cpp(153,5)
   <Remainder>
   LOOP END
LOOP END

    Report from: Code generation optimizations [cg]

./MPI_OpenMP/wave_block0_1_kernel_omp_kernel.cpp(27,23):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (8, 0), and destination (alignment, offset): (16, 0)
./MPI_OpenMP/wave_block0_1_kernel_omp_kernel.cpp(27,29):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (8, 0), and destination (alignment, offset): (16, 8)
./MPI_OpenMP/wave_block0_1_kernel_omp_kernel.cpp(124,5):remark #34026: call to memcpy implemented as a call to optimized library version
./MPI_OpenMP/wave_block0_1_kernel_omp_kernel.cpp(133,5):remark #34026: call to memcpy implemented as a call to optimized library version
./MPI_OpenMP/wave_block0_1_kernel_omp_kernel.cpp(21,30):remark #34051: REGISTER ALLOCATION : [_Z33ops_par_loop_wave_block0_1_kernelPKcP14ops_block_coreiPi7ops_argS4_] ./MPI_OpenMP/wave_block0_1_kernel_omp_kernel.cpp:21

    Hardware registers
        Reserved     :    2[ rsp rip]
        Available    :   39[ rax rdx rcx rbx rbp rsi rdi r8-r15 mm0-mm7 zmm0-zmm15]
        Callee-save  :    6[ rbx rbp r12-r15]
        Assigned     :   21[ rax rdx rcx rbx rbp rsi rdi r8-r15 zmm0-zmm5]
        
    Routine temporaries
        Total         :     354
            Global    :      89
            Local     :     265
        Regenerable   :     101
        Spilled       :      34
        
    Routine stack
        Variables     :     208 bytes*
            Reads     :      20 [1.24e+01 ~ 0.9%]
            Writes    :      22 [7.70e+01 ~ 5.8%]
        Spills        :     320 bytes*
            Reads     :      62 [1.31e+02 ~ 9.9%]
            Writes    :      47 [3.79e+01 ~ 2.9%]
    
    Notes
    
        *Non-overlapping variables and spills may share stack space,
         so the total stack size might be less than this.
    

===========================================================================

Begin optimization report for: ops_par_loop_wave_block0_2_kernel(const char *, ops_block, int, int *, ops_arg, ops_arg, ops_arg, ops_arg)

    Report from: Interprocedural optimizations [ipo]

INLINE REPORT: (ops_par_loop_wave_block0_2_kernel(const char *, ops_block, int, int *, ops_arg, ops_arg, ops_arg, ops_arg)) [5] ./MPI_OpenMP/wave_block0_2_kernel_omp_kernel.cpp(21,58)
  -> INLINE: (160,9) wave_block0_2_kernel(const double *, const double *, double *, const double *)
  -> INLINE: (173,7) wave_block0_2_kernel(const double *, const double *, double *, const double *)


    Report from: OpenMP optimizations [openmp]

./MPI_OpenMP/wave_block0_2_kernel_omp_kernel.cpp(112:3-112:3):OMP:_Z33ops_par_loop_wave_block0_2_kernelPKcP14ops_block_coreiPi7ops_argS4_S4_S4_:  OpenMP DEFINED LOOP WAS PARALLELIZED

    Report from: Loop nest, Vector & Auto-parallelization optimizations [loop, vec, par]


LOOP BEGIN at ./MPI_OpenMP/wave_block0_2_kernel_omp_kernel.cpp(113,3)
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at ./MPI_OpenMP/wave_block0_2_kernel_omp_kernel.cpp(129,5)
      remark #25399: memcopy generated
      remark #15542: loop was not vectorized: inner loop was already vectorized

      LOOP BEGIN at ./MPI_OpenMP/wave_block0_2_kernel_omp_kernel.cpp(129,5)
      <Peeled loop for vectorization>
      LOOP END

      LOOP BEGIN at ./MPI_OpenMP/wave_block0_2_kernel_omp_kernel.cpp(129,5)
         remark #15300: LOOP WAS VECTORIZED
      LOOP END

      LOOP BEGIN at ./MPI_OpenMP/wave_block0_2_kernel_omp_kernel.cpp(129,5)
      <Alternate Alignment Vectorized Loop>
      LOOP END

      LOOP BEGIN at ./MPI_OpenMP/wave_block0_2_kernel_omp_kernel.cpp(129,5)
      <Remainder loop for vectorization>
      LOOP END
   LOOP END

   LOOP BEGIN at ./MPI_OpenMP/wave_block0_2_kernel_omp_kernel.cpp(138,5)
      remark #25399: memcopy generated
      remark #15542: loop was not vectorized: inner loop was already vectorized

      LOOP BEGIN at ./MPI_OpenMP/wave_block0_2_kernel_omp_kernel.cpp(138,5)
         remark #15300: LOOP WAS VECTORIZED
      LOOP END

      LOOP BEGIN at ./MPI_OpenMP/wave_block0_2_kernel_omp_kernel.cpp(138,5)
      <Remainder loop for vectorization>
      LOOP END
   LOOP END

   LOOP BEGIN at ./MPI_OpenMP/wave_block0_2_kernel_omp_kernel.cpp(147,5)
      remark #25399: memcopy generated
      remark #15542: loop was not vectorized: inner loop was already vectorized

      LOOP BEGIN at ./MPI_OpenMP/wave_block0_2_kernel_omp_kernel.cpp(147,5)
         remark #15300: LOOP WAS VECTORIZED
      LOOP END

      LOOP BEGIN at ./MPI_OpenMP/wave_block0_2_kernel_omp_kernel.cpp(147,5)
      <Remainder loop for vectorization>
      LOOP END
   LOOP END

   LOOP BEGIN at ./MPI_OpenMP/wave_block0_2_kernel_omp_kernel.cpp(156,5)
      remark #15542: loop was not vectorized: inner loop was already vectorized

      LOOP BEGIN at ./MPI_OpenMP/wave_block0_2_kernel_omp_kernel.cpp(159,7)
         remark #15301: SIMD LOOP WAS VECTORIZED
      LOOP END
   LOOP END

   LOOP BEGIN at ./MPI_OpenMP/wave_block0_2_kernel_omp_kernel.cpp(171,5)
      remark #15300: LOOP WAS VECTORIZED
   LOOP END

   LOOP BEGIN at ./MPI_OpenMP/wave_block0_2_kernel_omp_kernel.cpp(171,5)
   <Remainder loop for vectorization>
   LOOP END
LOOP END

Fusion of IFs performed in _Z33ops_par_loop_wave_block0_2_kernelPKcP14ops_block_coreiPi7ops_argS4_S4_S4_ at line 138

    Report from: Code generation optimizations [cg]

./MPI_OpenMP/wave_block0_2_kernel_omp_kernel.cpp(27,23):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (8, 0), and destination (alignment, offset): (16, 0)
./MPI_OpenMP/wave_block0_2_kernel_omp_kernel.cpp(27,29):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (8, 0), and destination (alignment, offset): (16, 8)
./MPI_OpenMP/wave_block0_2_kernel_omp_kernel.cpp(27,35):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (8, 0), and destination (alignment, offset): (16, 0)
./MPI_OpenMP/wave_block0_2_kernel_omp_kernel.cpp(27,41):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (8, 0), and destination (alignment, offset): (16, 8)
./MPI_OpenMP/wave_block0_2_kernel_omp_kernel.cpp(129,5):remark #34026: call to memcpy implemented as a call to optimized library version
./MPI_OpenMP/wave_block0_2_kernel_omp_kernel.cpp(138,5):remark #34026: call to memcpy implemented as a call to optimized library version
./MPI_OpenMP/wave_block0_2_kernel_omp_kernel.cpp(147,5):remark #34026: call to memcpy implemented as a call to optimized library version
./MPI_OpenMP/wave_block0_2_kernel_omp_kernel.cpp(21,58):remark #34051: REGISTER ALLOCATION : [_Z33ops_par_loop_wave_block0_2_kernelPKcP14ops_block_coreiPi7ops_argS4_S4_S4_] ./MPI_OpenMP/wave_block0_2_kernel_omp_kernel.cpp:21

    Hardware registers
        Reserved     :    2[ rsp rip]
        Available    :   39[ rax rdx rcx rbx rbp rsi rdi r8-r15 mm0-mm7 zmm0-zmm15]
        Callee-save  :    6[ rbx rbp r12-r15]
        Assigned     :   28[ rax rdx rcx rbx rbp rsi rdi r8-r15 zmm0-zmm12]
        
    Routine temporaries
        Total         :     493
            Global    :     125
            Local     :     368
        Regenerable   :     111
        Spilled       :      63
        
    Routine stack
        Variables     :     328 bytes*
            Reads     :      25 [1.80e+01 ~ 0.6%]
            Writes    :      34 [1.06e+02 ~ 3.3%]
        Spills        :     552 bytes*
            Reads     :     115 [3.90e+02 ~ 12.0%]
            Writes    :      81 [1.02e+02 ~ 3.1%]
    
    Notes
    
        *Non-overlapping variables and spills may share stack space,
         so the total stack size might be less than this.
    

===========================================================================

Begin optimization report for: ops_par_loop_wave_block0_3_kernel(const char *, ops_block, int, int *, ops_arg, ops_arg, ops_arg)

    Report from: Interprocedural optimizations [ipo]

INLINE REPORT: (ops_par_loop_wave_block0_3_kernel(const char *, ops_block, int, int *, ops_arg, ops_arg, ops_arg)) [6] ./MPI_OpenMP/wave_block0_3_kernel_omp_kernel.cpp(21,44)
  -> INLINE: (146,9) wave_block0_3_kernel(const double *, double *, const double *)
  -> INLINE: (157,7) wave_block0_3_kernel(const double *, double *, const double *)


    Report from: OpenMP optimizations [openmp]

./MPI_OpenMP/wave_block0_3_kernel_omp_kernel.cpp(107:3-107:3):OMP:_Z33ops_par_loop_wave_block0_3_kernelPKcP14ops_block_coreiPi7ops_argS4_S4_:  OpenMP DEFINED LOOP WAS PARALLELIZED

    Report from: Loop nest, Vector & Auto-parallelization optimizations [loop, vec, par]


LOOP BEGIN at ./MPI_OpenMP/wave_block0_3_kernel_omp_kernel.cpp(108,3)
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at ./MPI_OpenMP/wave_block0_3_kernel_omp_kernel.cpp(124,5)
      remark #25399: memcopy generated
      remark #15542: loop was not vectorized: inner loop was already vectorized

      LOOP BEGIN at ./MPI_OpenMP/wave_block0_3_kernel_omp_kernel.cpp(124,5)
      <Peeled loop for vectorization>
      LOOP END

      LOOP BEGIN at ./MPI_OpenMP/wave_block0_3_kernel_omp_kernel.cpp(124,5)
         remark #15300: LOOP WAS VECTORIZED
      LOOP END

      LOOP BEGIN at ./MPI_OpenMP/wave_block0_3_kernel_omp_kernel.cpp(124,5)
      <Alternate Alignment Vectorized Loop>
      LOOP END

      LOOP BEGIN at ./MPI_OpenMP/wave_block0_3_kernel_omp_kernel.cpp(124,5)
      <Remainder loop for vectorization>
      LOOP END
   LOOP END

   LOOP BEGIN at ./MPI_OpenMP/wave_block0_3_kernel_omp_kernel.cpp(133,5)
      remark #25399: memcopy generated
      remark #15542: loop was not vectorized: inner loop was already vectorized

      LOOP BEGIN at ./MPI_OpenMP/wave_block0_3_kernel_omp_kernel.cpp(133,5)
         remark #15300: LOOP WAS VECTORIZED
      LOOP END

      LOOP BEGIN at ./MPI_OpenMP/wave_block0_3_kernel_omp_kernel.cpp(133,5)
      <Remainder loop for vectorization>
      LOOP END
   LOOP END

   LOOP BEGIN at ./MPI_OpenMP/wave_block0_3_kernel_omp_kernel.cpp(142,5)
      remark #15542: loop was not vectorized: inner loop was already vectorized

      LOOP BEGIN at ./MPI_OpenMP/wave_block0_3_kernel_omp_kernel.cpp(145,7)
         remark #15301: SIMD LOOP WAS VECTORIZED
      LOOP END
   LOOP END

   LOOP BEGIN at ./MPI_OpenMP/wave_block0_3_kernel_omp_kernel.cpp(155,5)
      remark #15344: loop was not vectorized: vector dependence prevents vectorization. First dependence is shown below. Use level 5 report for details
      remark #15346: vector dependence: assumed FLOW dependence between *norm_alias_2P64 (12:1) and *norm_alias_2P64 (12:1)
      remark #25439: unrolled with remainder by 2  
   LOOP END

   LOOP BEGIN at ./MPI_OpenMP/wave_block0_3_kernel_omp_kernel.cpp(155,5)
   <Remainder>
   LOOP END
LOOP END

    Report from: Code generation optimizations [cg]

./MPI_OpenMP/wave_block0_3_kernel_omp_kernel.cpp(27,23):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (8, 0), and destination (alignment, offset): (16, 0)
./MPI_OpenMP/wave_block0_3_kernel_omp_kernel.cpp(27,29):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (8, 0), and destination (alignment, offset): (16, 8)
./MPI_OpenMP/wave_block0_3_kernel_omp_kernel.cpp(27,35):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (8, 0), and destination (alignment, offset): (16, 0)
./MPI_OpenMP/wave_block0_3_kernel_omp_kernel.cpp(124,5):remark #34026: call to memcpy implemented as a call to optimized library version
./MPI_OpenMP/wave_block0_3_kernel_omp_kernel.cpp(133,5):remark #34026: call to memcpy implemented as a call to optimized library version
./MPI_OpenMP/wave_block0_3_kernel_omp_kernel.cpp(21,44):remark #34051: REGISTER ALLOCATION : [_Z33ops_par_loop_wave_block0_3_kernelPKcP14ops_block_coreiPi7ops_argS4_S4_] ./MPI_OpenMP/wave_block0_3_kernel_omp_kernel.cpp:21

    Hardware registers
        Reserved     :    2[ rsp rip]
        Available    :   39[ rax rdx rcx rbx rbp rsi rdi r8-r15 mm0-mm7 zmm0-zmm15]
        Callee-save  :    6[ rbx rbp r12-r15]
        Assigned     :   24[ rax rdx rcx rbx rbp rsi rdi r8-r15 zmm0-zmm8]
        
    Routine temporaries
        Total         :     370
            Global    :      90
            Local     :     280
        Regenerable   :     101
        Spilled       :      35
        
    Routine stack
        Variables     :     264 bytes*
            Reads     :      20 [1.24e+01 ~ 0.8%]
            Writes    :      26 [8.10e+01 ~ 5.3%]
        Spills        :     328 bytes*
            Reads     :      67 [1.47e+02 ~ 9.6%]
            Writes    :      49 [4.18e+01 ~ 2.7%]
    
    Notes
    
        *Non-overlapping variables and spills may share stack space,
         so the total stack size might be less than this.
    

===========================================================================

Begin optimization report for: ops_par_loop_wave_block0_5_kernel(const char *, ops_block, int, int *, ops_arg, ops_arg)

    Report from: Interprocedural optimizations [ipo]

INLINE REPORT: (ops_par_loop_wave_block0_5_kernel(const char *, ops_block, int, int *, ops_arg, ops_arg)) [7] ./MPI_OpenMP/wave_block0_5_kernel_omp_kernel.cpp(21,30)
  -> INLINE: (137,9) wave_block0_5_kernel(double *, const int *)
  -> INLINE: (148,7) wave_block0_5_kernel(double *, const int *)


    Report from: OpenMP optimizations [openmp]

./MPI_OpenMP/wave_block0_5_kernel_omp_kernel.cpp(102:3-102:3):OMP:_Z33ops_par_loop_wave_block0_5_kernelPKcP14ops_block_coreiPi7ops_argS4_:  OpenMP DEFINED LOOP WAS PARALLELIZED

    Report from: Loop nest, Vector & Auto-parallelization optimizations [loop, vec, par]


LOOP BEGIN at ./MPI_OpenMP/wave_block0_5_kernel_omp_kernel.cpp(103,3)
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at ./MPI_OpenMP/wave_block0_5_kernel_omp_kernel.cpp(125,5)
      remark #25399: memcopy generated
      remark #15542: loop was not vectorized: inner loop was already vectorized

      LOOP BEGIN at ./MPI_OpenMP/wave_block0_5_kernel_omp_kernel.cpp(125,5)
      <Peeled loop for vectorization>
      LOOP END

      LOOP BEGIN at ./MPI_OpenMP/wave_block0_5_kernel_omp_kernel.cpp(125,5)
         remark #15300: LOOP WAS VECTORIZED
      LOOP END

      LOOP BEGIN at ./MPI_OpenMP/wave_block0_5_kernel_omp_kernel.cpp(125,5)
      <Alternate Alignment Vectorized Loop>
      LOOP END

      LOOP BEGIN at ./MPI_OpenMP/wave_block0_5_kernel_omp_kernel.cpp(125,5)
      <Remainder loop for vectorization>
      LOOP END
   LOOP END

   LOOP BEGIN at ./MPI_OpenMP/wave_block0_5_kernel_omp_kernel.cpp(134,5)
      remark #15335: loop was not vectorized: vectorization possible but seems inefficient. Use vector always directive or -vec-threshold0 to override 
      remark #25456: Number of Array Refs Scalar Replaced In Loop: 1

      LOOP BEGIN at ./MPI_OpenMP/wave_block0_5_kernel_omp_kernel.cpp(136,18)
         remark #25084: Preprocess Loopnests: Moving Out Store    [ ./MPI_OpenMP/wave_block0_5_kernel_omp_kernel.cpp(139,9) ]
         remark #25436: completely unrolled by 4   (pre-vector) 
      LOOP END
   LOOP END

   LOOP BEGIN at ./MPI_OpenMP/wave_block0_5_kernel_omp_kernel.cpp(146,5)
      remark #25084: Preprocess Loopnests: Moving Out Store    [ ./MPI_OpenMP/wave_block0_5_kernel_omp_kernel.cpp(153,7) ]
      remark #15335: loop was not vectorized: vectorization possible but seems inefficient. Use vector always directive or -vec-threshold0 to override 
   LOOP END
LOOP END

    Report from: Code generation optimizations [cg]

./MPI_OpenMP/wave_block0_5_kernel_omp_kernel.cpp(27,23):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (8, 0), and destination (alignment, offset): (16, 0)
./MPI_OpenMP/wave_block0_5_kernel_omp_kernel.cpp(27,29):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (8, 0), and destination (alignment, offset): (16, 8)
./MPI_OpenMP/wave_block0_5_kernel_omp_kernel.cpp(125,5):remark #34026: call to memcpy implemented as a call to optimized library version
./MPI_OpenMP/wave_block0_5_kernel_omp_kernel.cpp(21,30):remark #34051: REGISTER ALLOCATION : [_Z33ops_par_loop_wave_block0_5_kernelPKcP14ops_block_coreiPi7ops_argS4_] ./MPI_OpenMP/wave_block0_5_kernel_omp_kernel.cpp:21

    Hardware registers
        Reserved     :    2[ rsp rip]
        Available    :   39[ rax rdx rcx rbx rbp rsi rdi r8-r15 mm0-mm7 zmm0-zmm15]
        Callee-save  :    6[ rbx rbp r12-r15]
        Assigned     :   21[ rax rdx rcx rbx rbp rsi rdi r8-r15 zmm0-zmm5]
        
    Routine temporaries
        Total         :     315
            Global    :      69
            Local     :     246
        Regenerable   :      91
        Spilled       :      26
        
    Routine stack
        Variables     :     200 bytes*
            Reads     :      15 [6.87e+00 ~ 0.4%]
            Writes    :      18 [5.61e+01 ~ 3.1%]
        Spills        :     240 bytes*
            Reads     :      47 [1.23e+02 ~ 6.9%]
            Writes    :      40 [4.94e+01 ~ 2.8%]
    
    Notes
    
        *Non-overlapping variables and spills may share stack space,
         so the total stack size might be less than this.
    

===========================================================================

Begin optimization report for: ops_arg_gbl<double>(double *, int, const char *, ops_access)

    Report from: Interprocedural optimizations [ipo]

DEAD STATIC FUNCTION: (ops_arg_gbl<double>(double *, int, const char *, ops_access)) /root/OPS/ops/c/include/ops_lib_cpp.h(77,73)

===========================================================================

Begin optimization report for: ops_decl_dat<double>(ops_block, int, int *, int *, int *, int *, double *, const char *, const char *)

    Report from: Interprocedural optimizations [ipo]

DEAD STATIC FUNCTION: (ops_decl_dat<double>(ops_block, int, int *, int *, int *, int *, double *, const char *, const char *)) /root/OPS/ops/c/include/ops_lib_cpp.h(140,40)

===========================================================================

Begin optimization report for: ops_decl_const2<int>(const char *, int, const char *, int *)

    Report from: Interprocedural optimizations [ipo]

DEAD STATIC FUNCTION: (ops_decl_const2<int>(const char *, int, const char *, int *)) /root/OPS/ops/c/include/ops_lib_cpp.h(82,76)

===========================================================================

Begin optimization report for: ops_decl_const2<double>(const char *, int, const char *, double *)

    Report from: Interprocedural optimizations [ipo]

DEAD STATIC FUNCTION: (ops_decl_const2<double>(const char *, int, const char *, double *)) /root/OPS/ops/c/include/ops_lib_cpp.h(82,76)

===========================================================================

Begin optimization report for: wave_block0_3_kernel(const double *, double *, const double *)

    Report from: Interprocedural optimizations [ipo]

DEAD STATIC FUNCTION: (wave_block0_3_kernel(const double *, double *, const double *)) ./MPI_OpenMP/wave_block0_3_kernel_omp_kernel.cpp(11,1)

===========================================================================

Begin optimization report for: wave_block0_2_kernel(const double *, const double *, double *, const double *)

    Report from: Interprocedural optimizations [ipo]

DEAD STATIC FUNCTION: (wave_block0_2_kernel(const double *, const double *, double *, const double *)) ./MPI_OpenMP/wave_block0_2_kernel_omp_kernel.cpp(11,1)

===========================================================================

Begin optimization report for: wave_block0_1_kernel(const double *, double *)

    Report from: Interprocedural optimizations [ipo]

DEAD STATIC FUNCTION: (wave_block0_1_kernel(const double *, double *)) ./MPI_OpenMP/wave_block0_1_kernel_omp_kernel.cpp(11,1)

===========================================================================

Begin optimization report for: wave_block0_0_kernel(const double *, double *)

    Report from: Interprocedural optimizations [ipo]

DEAD STATIC FUNCTION: (wave_block0_0_kernel(const double *, double *)) ./MPI_OpenMP/wave_block0_0_kernel_omp_kernel.cpp(11,1)

===========================================================================

Begin optimization report for: wave_block0_4_kernel(const double *, double *)

    Report from: Interprocedural optimizations [ipo]

DEAD STATIC FUNCTION: (wave_block0_4_kernel(const double *, double *)) ./MPI_OpenMP/wave_block0_4_kernel_omp_kernel.cpp(11,1)

===========================================================================

Begin optimization report for: wave_block0_5_kernel(double *, const int *)

    Report from: Interprocedural optimizations [ipo]

DEAD STATIC FUNCTION: (wave_block0_5_kernel(double *, const int *)) ./MPI_OpenMP/wave_block0_5_kernel_omp_kernel.cpp(11,1)

===========================================================================

Begin optimization report for: type_error(const double *, const char *)

    Report from: Interprocedural optimizations [ipo]

DEAD STATIC FUNCTION: (type_error(const double *, const char *)) /root/OPS/ops/c/include/ops_lib_cpp.h(47,58)

===========================================================================

Begin optimization report for: type_error(const int *, const char *)

    Report from: Interprocedural optimizations [ipo]

DEAD STATIC FUNCTION: (type_error(const int *, const char *)) /root/OPS/ops/c/include/ops_lib_cpp.h(55,55)

===========================================================================

    Report from: Profile guided optimizations [pgo]



Profile feedback used a statically estimated profile for the following routines:

  File: ./MPI_OpenMP/wave_block0_0_kernel_omp_kernel.cpp
        ops_par_loop_wave_block0_0_kernel(const char *, ops_block, int, int *, ops_arg, ops_arg)[Line    21]

  File: ./MPI_OpenMP/wave_block0_1_kernel_omp_kernel.cpp
        ops_par_loop_wave_block0_1_kernel(const char *, ops_block, int, int *, ops_arg, ops_arg)[Line    21]

  File: ./MPI_OpenMP/wave_block0_2_kernel_omp_kernel.cpp
        ops_par_loop_wave_block0_2_kernel(const char *, ops_block, int, int *, ops_arg, ops_arg, ops_arg, ops_arg)[Line    21]

  File: ./MPI_OpenMP/wave_block0_3_kernel_omp_kernel.cpp
        ops_par_loop_wave_block0_3_kernel(const char *, ops_block, int, int *, ops_arg, ops_arg, ops_arg)[Line    21]

  File: ./MPI_OpenMP/wave_block0_4_kernel_omp_kernel.cpp
        ops_par_loop_wave_block0_4_kernel(const char *, ops_block, int, int *, ops_arg, ops_arg)[Line    21]

  File: ./MPI_OpenMP/wave_block0_5_kernel_omp_kernel.cpp
        ops_par_loop_wave_block0_5_kernel(const char *, ops_block, int, int *, ops_arg, ops_arg)[Line    21]

  File: wave_ops.cpp
        main(int, char **)                                                [Line    57]


  0 out of 7 routine(s) used training profile data for PGO feedback
  0 out of 7 routine(s) were unable to use training profile data for PGO feedback
  0 out of 7 routine(s) were unable to find training profile data for PGO feedback
  7 out of 7 routine(s) used a static estimate profile for PGO feedback



